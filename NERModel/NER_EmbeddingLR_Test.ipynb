{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8090e10-ee4a-4c24-b1af-8008b65a64ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8096 entries, 0 to 8095\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  8096 non-null   object\n",
      " 1   Tag       8096 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 126.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Families of soldiers killed in the conflict jo...   \n",
       "2  They marched from the Houses of Parliament to ...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, f1_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from wordcloud import WordCloud \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load Data from .csv file\n",
    "df = pd.read_csv(\"./TalkFile_ner_2.csv\")\n",
    "df.drop(['Sentence #', 'POS'], axis=1, inplace=True)\n",
    "df = df.dropna()  # Remove Blank Text\n",
    "\n",
    "df = df.iloc[:8096]\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9c1938-30c7-4159-8b40-9eca378e6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = \" \".join(df[\"Sentence\"]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f71b00-906e-4f1f-8a3e-46342d769b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'demonstrators', 'have', 'marched']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8654c42-7899-45f1-a716-c9a28d8251f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14551"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word indexing and Vectorization\n",
    "word2idx = {'<pad>': 0}\n",
    "word2idx.update({word: idx+1 for idx, word in enumerate(set(all_words))})\n",
    "vocab_size = len(word2idx)\n",
    "vocab_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9ef0f7-c6b7-4b1e-92a1-d7674fee9be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands',\n",
       " 'of',\n",
       " 'demonstrators',\n",
       " 'have',\n",
       " 'marched',\n",
       " 'through',\n",
       " 'London',\n",
       " 'to',\n",
       " 'protest',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'withdrawal',\n",
       " 'of',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'from',\n",
       " 'that',\n",
       " 'country',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences = df[\"Sentence\"].str.split()\n",
    "Sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223feefe-7477-4b75-bd9c-92d801c80663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove square brackets, commas, and quotation marks from the \"Tag\" column\n",
    "df[\"Tag_stripe\"] = df[\"Tag\"].str.replace(r\"[\\[\\]',]\", '', regex=True)\n",
    "\n",
    "# Combine all values in the \"Tag\" column into a single string\n",
    "cleaned_tags = \" \".join(df[\"Tag_stripe\"]).split()\n",
    "\n",
    "# Get unique tags\n",
    "unique_tags = set(cleaned_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c06926f-f8c3-4893-82c3-38269dced977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       O O O O O O B-geo O O O O O B-geo O O O O O B-...\n",
       "1       O O O O O O O O O O O O O O O O O O B-per O O ...\n",
       "2                     O O O O O O O O O O O B-geo I-geo O\n",
       "3                           O O O O O O O O O O O O O O O\n",
       "4       O O O O O O O O O O O B-geo O O B-org I-org O ...\n",
       "                              ...                        \n",
       "8091    O O O O O O O B-geo I-geo O O O O O O O O O O ...\n",
       "8092    O O O O O O O O O O O O O O O O O O B-geo I-geo O\n",
       "8093    B-org I-org O O B-org I-org O O O O O O O O O ...\n",
       "8094    O O O O O O O O O O O B-tim O O O O O O O O O ...\n",
       "8095    O O B-geo I-geo O O O O O O O O B-tim O O O O ...\n",
       "Name: Tag_stripe, Length: 8096, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tag_stripe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e217c4e-4bc0-48ea-9157-f68d8feeb4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d745797b-9bca-45a2-b9e4-2b827558e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "list_labels = ['O'] + [i for i in list(unique_tags) if i !='O']\n",
    "\n",
    "label2ind = {}\n",
    "ind2label = {}\n",
    "for ind, i in enumerate(list_labels):\n",
    "    label2ind[i]=ind\n",
    "    ind2label[ind]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd569e5-b4bb-4c02-91df-7bac052e192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-per',\n",
       " 2: 'I-nat',\n",
       " 3: 'I-art',\n",
       " 4: 'B-art',\n",
       " 5: 'I-gpe',\n",
       " 6: 'B-eve',\n",
       " 7: 'I-geo',\n",
       " 8: 'I-eve',\n",
       " 9: 'B-nat',\n",
       " 10: 'I-tim',\n",
       " 11: 'B-org',\n",
       " 12: 'B-geo',\n",
       " 13: 'B-gpe',\n",
       " 14: 'B-tim',\n",
       " 15: 'I-org',\n",
       " 16: 'I-per'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24338416-a5e4-4231-b6da-3b8512982dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-per': 1,\n",
       " 'I-nat': 2,\n",
       " 'I-art': 3,\n",
       " 'B-art': 4,\n",
       " 'I-gpe': 5,\n",
       " 'B-eve': 6,\n",
       " 'I-geo': 7,\n",
       " 'I-eve': 8,\n",
       " 'B-nat': 9,\n",
       " 'I-tim': 10,\n",
       " 'B-org': 11,\n",
       " 'B-geo': 12,\n",
       " 'B-gpe': 13,\n",
       " 'B-tim': 14,\n",
       " 'I-org': 15,\n",
       " 'I-per': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e96ebdeb-0b11-4e9d-8390-edb6874a65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +1 for <pad>\n",
    "num_class = len(label2ind) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb73159-d5d0-483e-8ff1-07b3b6047973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8096 entries, 0 to 8095\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Sentence       8096 non-null   object\n",
      " 1   Tag            8096 non-null   object\n",
      " 2   Tag_stripe     8096 non-null   object\n",
      " 3   Encoded_Words  8096 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 253.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Tag_stripe</th>\n",
       "      <th>Encoded_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "      <td>[11709, 5148, 9880, 7590, 2943, 9060, 7126, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O B-per O O ...</td>\n",
       "      <td>[1134, 5148, 5684, 8312, 2449, 1614, 3193, 113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O B-geo I-geo O</td>\n",
       "      <td>[12937, 2943, 13074, 1614, 173, 5148, 13761, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O</td>\n",
       "      <td>[11403, 5898, 1614, 8994, 5148, 901, 11692, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O B-geo O O B-org I-org O ...</td>\n",
       "      <td>[10820, 7954, 7462, 12440, 1614, 10498, 5148, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Families of soldiers killed in the conflict jo...   \n",
       "2  They marched from the Houses of Parliament to ...   \n",
       "3  Police put the number of marchers at 10,000 wh...   \n",
       "4  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...   \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "\n",
       "                                          Tag_stripe  \\\n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...   \n",
       "1  O O O O O O O O O O O O O O O O O O B-per O O ...   \n",
       "2                O O O O O O O O O O O B-geo I-geo O   \n",
       "3                      O O O O O O O O O O O O O O O   \n",
       "4  O O O O O O O O O O O B-geo O O B-org I-org O ...   \n",
       "\n",
       "                                       Encoded_Words  \n",
       "0  [11709, 5148, 9880, 7590, 2943, 9060, 7126, 12...  \n",
       "1  [1134, 5148, 5684, 8312, 2449, 1614, 3193, 113...  \n",
       "2  [12937, 2943, 13074, 1614, 173, 5148, 13761, 1...  \n",
       "3  [11403, 5898, 1614, 8994, 5148, 901, 11692, 13...  \n",
       "4  [10820, 7954, 7462, 12440, 1614, 10498, 5148, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to encode a list of words upto max_length\n",
    "def encode_sentence(words, word2idx, max_length):\n",
    "    # Encode words into indices, using 0 for unknown words\n",
    "    encoded = [word2idx.get(word, 0) for word in words]\n",
    "    \n",
    "    # Pad or truncate the list to match max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded.extend([0] * (max_length - len(encoded)))  # Pad with zeros\n",
    "    else:\n",
    "        encoded = encoded[:max_length]  # Truncate to max_length\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# Encode each list of words\n",
    "MAX_LEN = max(len(x) for x in Sentences)  # Ensure you have defined max_len appropriately\n",
    "max_len = MAX_LEN\n",
    "\n",
    "df[\"Encoded_Words\"] = Sentences.apply(lambda words: encode_sentence(words, word2idx, max_len))\n",
    "df.info()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b0b1aa1-185c-4971-899d-3b203b1d50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a list of POS or NER labels up to max_length\n",
    "def label_vectors(labels, max_length):\n",
    "    # Encode words into indices, using 0 for unknown words\n",
    "    encoded = [label2ind.get(label, len(label2ind)) for label in labels.split()]  # Use .get to handle unknown labels\n",
    "    \n",
    "    # Pad or truncate the list to match max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded.extend([len(label2ind)] * (max_length - len(encoded)))  # Pad with len(label2ind)\n",
    "    else:\n",
    "        encoded = encoded[:max_length]  # Truncate to max_length\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# Apply the function to the 'Tag' column and create a new column 'Label_Words'\n",
    "df[\"Label_Words\"] = df[\"Tag_stripe\"].apply(lambda labels: label_vectors(labels, max_len))\n",
    "\n",
    "df.drop(['Sentence', 'Tag_stripe', 'Tag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda68759-6ea8-4f68-a55a-a29db7d66c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split of the Dataset\n",
    "X = df[\"Encoded_Words\"].tolist()\n",
    "Y = df[\"Label_Words\"].tolist()\n",
    "\n",
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X, Y, train_size=0.8, random_state=101)\n",
    "\n",
    "# One hot for multi-class classification\n",
    "# NER = 17 classes [0-16] ==> num_class = 17 + 1 (padding)\n",
    "Y_trn_Oh = np.zeros((len(Y_trn), max_len, num_class))\n",
    "Y_tst_Oh = np.zeros((len(Y_tst), max_len, num_class))\n",
    "\n",
    "for i, y in enumerate(Y_trn):\n",
    "    Y_trn_Oh[i, np.arange(len(y)), y] = 1\n",
    "\n",
    "for i, y in enumerate(Y_tst):\n",
    "    Y_tst_Oh[i, np.arange(len(y)), y] = 1\n",
    "\n",
    "# Initialize an Embedding layer from Torch\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# Convert to word_vector Tensor \n",
    "X_train = torch.tensor(X_trn, dtype=torch.long)\n",
    "Y_train = torch.tensor(Y_trn_Oh, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_tst, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_tst_Oh, dtype=torch.float32)\n",
    "\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263d593a-f114-43aa-8418-cce557e3b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking parameters:  OrderedDict([('embedding.weight', tensor([[ 1.7650,  0.0664, -0.0706,  ..., -0.4957, -0.8165, -0.0069],\n",
      "        [-2.0248,  0.7593, -1.6994,  ..., -1.0252, -1.1372,  1.0307],\n",
      "        [-0.1482,  1.1154, -1.1194,  ..., -0.1613,  0.1007,  0.9505],\n",
      "        ...,\n",
      "        [-0.3324, -1.3870, -1.4919,  ..., -1.1009,  0.7484,  0.9779],\n",
      "        [-0.3785,  1.9315,  0.8482,  ..., -0.0449,  0.4784,  0.3803],\n",
      "        [-1.0563, -0.5742,  0.3903,  ...,  1.5642,  0.1007,  0.8791]])), ('linear.weight', tensor([[-0.1589, -0.1039, -0.1377, -0.0731,  0.1390, -0.1290,  0.0517,  0.0284,\n",
      "          0.0344,  0.0201,  0.0038, -0.1689, -0.0252, -0.1611, -0.0971,  0.0831,\n",
      "          0.0219,  0.1755,  0.1874, -0.1846,  0.0241, -0.1999,  0.0196, -0.1578],\n",
      "        [ 0.0518, -0.1570, -0.1798, -0.1783, -0.0462,  0.0585,  0.0034,  0.1813,\n",
      "          0.0167,  0.0602,  0.0694,  0.0134,  0.1817, -0.0510,  0.0708, -0.0440,\n",
      "         -0.0757, -0.0908,  0.1301, -0.1053, -0.0254,  0.1117,  0.0320, -0.1300],\n",
      "        [ 0.2025,  0.1698,  0.0152, -0.0876, -0.1051, -0.0996, -0.1414, -0.1949,\n",
      "         -0.1857, -0.1656,  0.1988, -0.1172, -0.0056,  0.0644,  0.1348,  0.1082,\n",
      "          0.0055, -0.0051, -0.1711, -0.1781,  0.0204,  0.0019,  0.0620, -0.1547],\n",
      "        [ 0.0862,  0.1832,  0.0441, -0.1777, -0.0508,  0.1969, -0.1429, -0.1094,\n",
      "         -0.1435, -0.1636, -0.1598,  0.1965, -0.0823, -0.0662, -0.0656, -0.0120,\n",
      "         -0.1655,  0.0416,  0.1172, -0.1222, -0.1156,  0.0591, -0.1443,  0.1791],\n",
      "        [ 0.1081, -0.1840,  0.1169, -0.0784, -0.1873, -0.0047,  0.1407,  0.1159,\n",
      "         -0.0614,  0.1556,  0.1478,  0.1748, -0.0165, -0.1434, -0.1190, -0.0318,\n",
      "          0.1295, -0.1636,  0.1649, -0.0351,  0.0311, -0.1181, -0.0044, -0.0105],\n",
      "        [ 0.0351,  0.1343,  0.1957,  0.1201, -0.1024, -0.0787, -0.1845, -0.0938,\n",
      "         -0.1143, -0.0371,  0.0483, -0.0052,  0.1812,  0.0349, -0.0379,  0.0434,\n",
      "          0.0396,  0.0018, -0.0499,  0.0167,  0.1258, -0.1332, -0.1970,  0.1815],\n",
      "        [-0.0287, -0.0555, -0.0056, -0.1057,  0.0139,  0.1018,  0.0447,  0.1264,\n",
      "         -0.1307, -0.0966,  0.0199,  0.0831,  0.0040, -0.0684,  0.1017,  0.1568,\n",
      "          0.0439, -0.1651, -0.0108,  0.1769, -0.1428, -0.1065, -0.1219, -0.0459],\n",
      "        [ 0.1044,  0.1248, -0.0944,  0.1577, -0.1264, -0.1159, -0.0640, -0.1021,\n",
      "         -0.0520, -0.0478,  0.1945,  0.0882, -0.0850,  0.0280,  0.1195,  0.1200,\n",
      "          0.0315,  0.1316,  0.1657,  0.1300, -0.1802,  0.1830, -0.0503, -0.1351],\n",
      "        [ 0.1667, -0.1858,  0.0131,  0.0926,  0.0382, -0.0396,  0.1545,  0.1319,\n",
      "          0.1769,  0.0368, -0.0385,  0.1923,  0.2034,  0.0423, -0.0512, -0.1132,\n",
      "         -0.1619, -0.1266,  0.1019,  0.1313, -0.1480,  0.0035,  0.1528, -0.1068],\n",
      "        [-0.1010, -0.1632, -0.1028, -0.1215, -0.0863, -0.1992, -0.1215,  0.1018,\n",
      "          0.1739, -0.0874, -0.0157, -0.1240,  0.0239, -0.0064, -0.0296,  0.1564,\n",
      "         -0.0802,  0.0004,  0.1976, -0.0220,  0.0261, -0.1316, -0.0193,  0.1768],\n",
      "        [ 0.0273, -0.0377, -0.0797,  0.0654, -0.1270,  0.0107,  0.0080,  0.1687,\n",
      "          0.1684, -0.0182,  0.0889, -0.0613,  0.0741, -0.1618, -0.1236, -0.0425,\n",
      "          0.1842,  0.0648,  0.0016, -0.1842,  0.0901, -0.0040,  0.1382, -0.1249],\n",
      "        [ 0.1785,  0.0341, -0.1328,  0.1491, -0.1645,  0.0291,  0.0195,  0.0758,\n",
      "          0.1716,  0.0940, -0.0979,  0.0911, -0.0523, -0.0235, -0.0704, -0.0884,\n",
      "         -0.1938, -0.1841, -0.0883, -0.1462,  0.0094, -0.1650,  0.0166, -0.0183],\n",
      "        [-0.1421,  0.0355, -0.1468,  0.1266,  0.0880, -0.1509, -0.1983,  0.1324,\n",
      "         -0.1098, -0.1121,  0.0517,  0.1968, -0.1244,  0.1222, -0.0836, -0.1723,\n",
      "         -0.0708, -0.0129,  0.0947, -0.0437,  0.1821,  0.0007,  0.0421, -0.1893],\n",
      "        [ 0.0811,  0.0595, -0.0214,  0.1545, -0.0204, -0.0445,  0.1416, -0.1920,\n",
      "          0.1613,  0.1785,  0.1492, -0.1921, -0.1067, -0.1937, -0.0747,  0.0511,\n",
      "         -0.1673, -0.0653,  0.1021,  0.0242,  0.0776, -0.0409, -0.0326,  0.0475],\n",
      "        [-0.1180, -0.1595,  0.1454, -0.1768,  0.0649, -0.2039,  0.1581, -0.0231,\n",
      "         -0.0029,  0.0829, -0.1196,  0.0042, -0.0454, -0.0611,  0.1951, -0.0446,\n",
      "         -0.1053,  0.1371,  0.1988,  0.0958,  0.0944, -0.0917, -0.1044,  0.1268],\n",
      "        [-0.1097,  0.1775, -0.0437,  0.1572, -0.0602,  0.1811, -0.1687, -0.0473,\n",
      "         -0.1558,  0.1339,  0.0846, -0.1063,  0.0668, -0.1758, -0.1746,  0.0101,\n",
      "          0.0226,  0.1955,  0.1927, -0.0911,  0.1683, -0.0793,  0.0398,  0.0735],\n",
      "        [ 0.1334, -0.1024,  0.0039, -0.0832, -0.0970,  0.1231, -0.0677, -0.0100,\n",
      "         -0.1485,  0.2026, -0.0612, -0.1510,  0.1356, -0.0313, -0.0788,  0.0398,\n",
      "          0.0422, -0.1593, -0.0202, -0.1873, -0.0059, -0.0277,  0.1610,  0.1391],\n",
      "        [-0.0517, -0.0609,  0.1580,  0.0217, -0.1373,  0.1005, -0.0318, -0.0164,\n",
      "         -0.1426,  0.0187,  0.1199, -0.1613,  0.1686,  0.0151,  0.0626, -0.0401,\n",
      "         -0.1892,  0.0253,  0.1002, -0.1594,  0.1416,  0.0375, -0.1970, -0.1518]])), ('linear.bias', tensor([-0.1039, -0.1941, -0.1943,  0.0168, -0.1363, -0.1135, -0.0082, -0.1382,\n",
      "        -0.1046, -0.1711, -0.1614,  0.1486,  0.0232, -0.0413,  0.1923,  0.1403,\n",
      "         0.1697, -0.1138]))])\n"
     ]
    }
   ],
   "source": [
    "# Build Custom Module for logistic Regression\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()  # Convert input tensor to LongTensor for embedding layer input\n",
    "        embedded = self.embedding(x)\n",
    "        y_pred = self.linear(embedded)  #  ?? no need for torch.sigmoid if using CrossEntropyLoss\n",
    "       # y_pred = nn.functional.softmax(y_pred, dim=1)\n",
    "        return y_pred\n",
    "        \n",
    "# Instantiate the model\n",
    "torch.manual_seed(27)\n",
    "# num_class = 17\n",
    "# vocab_size = 35177\n",
    "embedding_dim = 24\n",
    "\n",
    "model = LogisticRegression(vocab_size, embedding_dim, num_class)\n",
    "\n",
    "print(\"checking parameters: \", model.state_dict())\n",
    "\n",
    "# Defining Binary Cross-Entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f04d9d-d2a2-46bd-a77f-a2124d73195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 8096 sentences up to 70 words, Word embedding: vocab_size 14551 embedding_dim 24\n",
      "epoch: 1/256, loss: 15.837945938110352 - 0% complete, 0.6551809310913086 elapsed\n",
      "epoch: 26/256, loss: 14.276017189025879 - 10% complete, 30.394771814346313 elapsed\n",
      "epoch: 51/256, loss: 14.2449369430542 - 19% complete, 56.64189863204956 elapsed\n",
      "epoch: 76/256, loss: 14.237953186035156 - 29% complete, 84.67865991592407 elapsed\n",
      "epoch: 101/256, loss: 14.239107131958008 - 39% complete, 114.37227296829224 elapsed\n",
      "epoch: 126/256, loss: 14.239192962646484 - 49% complete, 145.5090525150299 elapsed\n",
      "epoch: 151/256, loss: 14.239192008972168 - 58% complete, 176.35077476501465 elapsed\n",
      "epoch: 176/256, loss: 14.239179611206055 - 68% complete, 209.1505196094513 elapsed\n",
      "epoch: 201/256, loss: 14.23917293548584 - 78% complete, 243.26292061805725 elapsed\n",
      "epoch: 226/256, loss: 14.239164352416992 - 88% complete, 277.4506051540375 elapsed\n",
      "epoch: 251/256, loss: 14.239158630371094 - 98% complete, 312.2679798603058 elapsed\n",
      "Loss: 14.24\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('embedding.weight', tensor([[ 9.7090e-01,  5.7640e-01,  4.5879e-03,  ..., -3.7125e-01,\n",
      "         -9.6228e-01, -6.8967e-01],\n",
      "        [-4.3748e-03, -3.0073e-04, -1.2634e-04,  ...,  5.1996e-06,\n",
      "          1.6846e-04,  1.1761e-04],\n",
      "        [ 2.0484e-41,  4.3634e-11, -5.2747e-11,  ..., -8.2556e-41,\n",
      "          3.5444e-41,  1.8922e-15],\n",
      "        ...,\n",
      "        [ 9.3866e-06, -1.0184e-04,  2.8908e-06,  ..., -4.2070e-06,\n",
      "          2.6040e-05,  2.4704e-05],\n",
      "        [-5.9747e-04,  8.2113e-04,  9.2236e-05,  ..., -5.8874e-05,\n",
      "          5.0233e-04,  2.7812e-04],\n",
      "        [ 1.8318e-04,  3.6209e-04, -7.2886e-05,  ...,  7.2204e-05,\n",
      "         -7.8837e-04, -6.6030e-05]])), ('linear.weight', tensor([[-6.2882e-01, -8.7694e-01,  5.6513e-02, -6.6230e-04,  6.8649e-01,\n",
      "         -5.3601e-01,  3.7257e-01,  2.5876e-01, -3.4437e-01, -3.7785e-01,\n",
      "          3.4535e-01, -7.1375e-01, -2.2592e-02,  2.7470e-01,  2.3752e-01,\n",
      "          5.9792e-01, -3.1122e-01, -5.3714e-01, -3.4545e-01,  1.6940e-01,\n",
      "         -1.6525e-01,  2.6645e-02,  4.7239e-01,  3.3567e-01],\n",
      "        [-2.0446e-01,  1.3164e-02, -1.9751e-02,  2.4939e-01,  1.0946e-01,\n",
      "         -3.1985e-01,  1.4587e-01,  2.6835e-01, -2.4190e-01, -1.6611e-01,\n",
      "          1.0968e-01,  1.0535e-02,  1.4618e-01,  1.2848e-01,  1.1142e-01,\n",
      "          1.4135e-01, -7.4599e-02,  1.7193e-03, -1.5650e-01,  3.2237e-01,\n",
      "         -1.4046e-01,  1.3202e-01,  2.3416e-01,  1.7375e-01],\n",
      "        [-1.0625e-02, -7.1378e-03, -3.6300e-04,  8.3633e-03,  8.9795e-03,\n",
      "         -1.3074e-02,  8.0986e-03,  1.0302e-02, -9.6473e-03, -8.5900e-03,\n",
      "          6.7304e-03, -5.8486e-03,  4.7163e-03,  6.8429e-03,  6.1692e-03,\n",
      "          9.4324e-03, -5.4291e-03, -5.0942e-03, -8.4568e-03,  1.1390e-02,\n",
      "         -6.6085e-03,  5.2618e-03,  1.0932e-02,  8.4686e-03],\n",
      "        [-2.0050e-02, -1.2335e-02,  7.4375e-05,  1.4240e-02,  1.6284e-02,\n",
      "         -2.5051e-02,  1.4111e-02,  1.8337e-02, -1.7893e-02, -1.4602e-02,\n",
      "          1.1619e-02, -1.0001e-02,  8.2565e-03,  1.1565e-02,  1.0240e-02,\n",
      "          1.6787e-02, -8.6362e-03, -8.6280e-03, -1.4728e-02,  2.0814e-02,\n",
      "         -1.1085e-02,  8.6672e-03,  1.9982e-02,  1.4874e-02],\n",
      "        [-3.6057e-02, -1.8977e-02,  5.3939e-05,  2.4338e-02,  2.7705e-02,\n",
      "         -4.5547e-02,  2.4033e-02,  3.3898e-02, -3.2183e-02, -2.5338e-02,\n",
      "          1.8761e-02, -1.5167e-02,  1.3841e-02,  1.8610e-02,  1.6420e-02,\n",
      "          2.8513e-02, -1.4238e-02, -1.1947e-02, -2.4950e-02,  3.7893e-02,\n",
      "         -1.7837e-02,  1.3368e-02,  3.5886e-02,  2.5040e-02],\n",
      "        [-2.3530e-02, -1.3422e-02, -5.6642e-04,  1.7056e-02,  1.8659e-02,\n",
      "         -2.9897e-02,  1.6008e-02,  2.1983e-02, -2.1273e-02, -1.7258e-02,\n",
      "          1.3394e-02, -1.0974e-02,  1.1845e-02,  1.3308e-02,  1.1687e-02,\n",
      "          1.9477e-02, -1.0220e-02, -9.2458e-03, -1.7155e-02,  2.5092e-02,\n",
      "         -1.2832e-02,  1.0110e-02,  2.3628e-02,  1.7356e-02],\n",
      "        [-3.0826e-02, -1.6784e-02, -3.0065e-04,  2.1185e-02,  2.3904e-02,\n",
      "         -3.9264e-02,  2.0449e-02,  2.8923e-02, -2.7866e-02, -2.2226e-02,\n",
      "          1.6443e-02, -1.3431e-02,  1.1588e-02,  1.6189e-02,  1.4215e-02,\n",
      "          2.4935e-02, -1.2491e-02, -1.0998e-02, -2.2002e-02,  3.2465e-02,\n",
      "         -1.5643e-02,  1.1574e-02,  3.0624e-02,  2.2069e-02],\n",
      "        [-1.6772e-01, -5.8517e-02, -6.6985e-03,  1.4167e-01,  1.1498e-01,\n",
      "         -2.2551e-01,  1.1371e-01,  1.7021e-01, -1.6097e-01, -1.1313e-01,\n",
      "          9.2426e-02, -4.8592e-02,  7.9570e-02,  9.3722e-02,  8.1300e-02,\n",
      "          1.2737e-01, -6.5713e-02, -4.1700e-02, -1.2093e-01,  2.0005e-01,\n",
      "         -9.7940e-02,  7.8490e-02,  1.7224e-01,  1.2552e-01],\n",
      "        [-2.4848e-02, -1.3908e-02, -6.1578e-05,  1.6899e-02,  1.9339e-02,\n",
      "         -3.1435e-02,  1.6420e-02,  2.2939e-02, -2.2141e-02, -1.7792e-02,\n",
      "          1.3491e-02, -1.1073e-02,  8.8897e-03,  1.2265e-02,  1.1383e-02,\n",
      "          2.0098e-02, -1.0183e-02, -9.1330e-03, -1.7469e-02,  2.5840e-02,\n",
      "         -1.2739e-02,  9.3542e-03,  2.4532e-02,  1.7474e-02],\n",
      "        [-1.9730e-02, -1.1586e-02, -1.2400e-04,  1.4126e-02,  1.6203e-02,\n",
      "         -2.6087e-02,  1.3787e-02,  1.9239e-02, -1.9402e-02, -1.4873e-02,\n",
      "          1.1520e-02, -9.2691e-03,  7.7211e-03,  1.1386e-02,  9.6385e-03,\n",
      "          1.6794e-02, -8.5294e-03, -7.5439e-03, -1.4603e-02,  2.1741e-02,\n",
      "         -1.0547e-02,  6.8069e-03,  2.0458e-02,  1.4726e-02],\n",
      "        [-1.5278e-01, -7.5150e-02, -1.8167e-03,  1.0756e-01,  1.1472e-01,\n",
      "         -1.9692e-01,  1.0063e-01,  1.4810e-01, -1.4257e-01, -1.1144e-01,\n",
      "          8.1985e-02, -6.1901e-02,  6.0418e-02,  8.0561e-02,  7.0354e-02,\n",
      "          1.2215e-01, -6.5007e-02, -5.1870e-02, -1.0674e-01,  1.6529e-01,\n",
      "         -7.9062e-02,  6.0659e-02,  1.4963e-01,  1.0952e-01],\n",
      "        [-2.2168e-01, -6.3826e-03, -1.7082e-02,  2.4209e-01,  1.2552e-01,\n",
      "         -3.2820e-01,  1.5186e-01,  2.7090e-01, -2.5360e-01, -1.6846e-01,\n",
      "          1.2080e-01, -4.9094e-03,  1.3365e-01,  1.2966e-01,  1.0462e-01,\n",
      "          1.5446e-01, -7.8204e-02, -1.5086e-02, -1.6667e-01,  3.2094e-01,\n",
      "         -1.4304e-01,  1.3012e-01,  2.4244e-01,  1.7844e-01],\n",
      "        [-2.4048e-01,  1.6027e-01, -2.5646e-02,  3.8298e-01,  7.4159e-02,\n",
      "         -4.2322e-01,  1.6992e-01,  3.8375e-01, -3.4375e-01, -1.7730e-01,\n",
      "          1.2823e-01,  1.5181e-01,  2.2233e-01,  1.5563e-01,  1.3876e-01,\n",
      "          1.3571e-01, -6.4118e-02,  8.1142e-02, -1.9300e-01,  4.6424e-01,\n",
      "         -1.9173e-01,  1.9933e-01,  2.9610e-01,  2.1204e-01],\n",
      "        [-2.0823e-01, -9.0710e-03,  6.8107e-04,  2.2691e-01,  1.1095e-01,\n",
      "         -3.1181e-01,  1.4173e-01,  2.5181e-01, -2.3357e-01, -1.6039e-01,\n",
      "          1.1352e-01, -6.1788e-03,  1.2808e-01,  1.1424e-01,  1.0534e-01,\n",
      "          1.4583e-01, -7.3965e-02, -1.2687e-02, -1.9881e-01,  3.8616e-01,\n",
      "         -1.3760e-01,  1.2047e-01,  2.2459e-01,  1.6660e-01],\n",
      "        [-2.1173e-01,  1.3016e-02, -1.7410e-02,  2.4524e-01,  1.1315e-01,\n",
      "         -3.2873e-01,  1.4732e-01,  2.7390e-01, -2.5498e-01, -1.8300e-01,\n",
      "          1.1454e-01,  1.2551e-02,  1.4478e-01,  1.2486e-01,  1.1012e-01,\n",
      "          1.5011e-01, -7.5729e-02,  1.9708e-03, -1.6643e-01,  3.3816e-01,\n",
      "         -1.4086e-01,  1.4157e-01,  2.3687e-01,  1.7147e-01],\n",
      "        [-2.1104e-01, -6.4206e-02, -1.0645e-02,  1.7698e-01,  1.4180e-01,\n",
      "         -2.8517e-01,  1.4524e-01,  2.2048e-01, -2.0901e-01, -1.5181e-01,\n",
      "          1.1357e-01, -5.2888e-02,  9.9234e-02,  1.1470e-01,  9.8722e-02,\n",
      "          1.5939e-01, -8.1485e-02, -5.1297e-02, -1.5010e-01,  2.5544e-01,\n",
      "         -1.2078e-01,  1.0113e-01,  2.1604e-01,  1.6436e-01],\n",
      "        [-2.2744e-01, -6.1614e-02, -1.5907e-02,  2.0578e-01,  1.4970e-01,\n",
      "         -3.1731e-01,  1.5119e-01,  2.4515e-01, -2.3201e-01, -1.6848e-01,\n",
      "          1.2556e-01, -5.0829e-02,  1.1386e-01,  1.2875e-01,  1.0913e-01,\n",
      "          1.7502e-01, -8.6727e-02, -5.1121e-02, -1.6472e-01,  2.8137e-01,\n",
      "         -1.3159e-01,  1.1577e-01,  2.3696e-01,  1.7104e-01],\n",
      "        [ 3.8489e-01,  3.1712e-01,  1.4193e-03, -3.1434e-01, -4.1713e-01,\n",
      "          5.4619e-01, -3.3246e-01, -4.2864e-01,  2.5526e-01,  3.6638e-01,\n",
      "         -2.3517e-01,  2.4802e-01, -1.6318e-01, -2.6089e-01, -2.2802e-01,\n",
      "         -4.1466e-01,  1.8616e-01,  2.0747e-01,  3.4832e-01, -4.9098e-01,\n",
      "          2.4650e-01, -1.8316e-01, -5.0264e-01, -3.4653e-01]])), ('linear.bias', tensor([-3.8799e-05,  2.5821e-07,  1.0297e-09, -4.1539e-08, -5.5855e-08,\n",
      "        -2.5462e-08,  1.6804e-07,  1.3381e-07, -1.7375e-09, -1.5638e-08,\n",
      "         1.1109e-08, -9.6667e-08,  1.4481e-06,  8.5053e-07,  4.5219e-07,\n",
      "         1.1029e-07, -6.3498e-07, -8.6375e-05]))])\n"
     ]
    }
   ],
   "source": [
    "# Hold the best model\n",
    "best_loss = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "n_epochs = 256  # number of epochs to run\n",
    "batch_size = 64  # size of each batch\n",
    "\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay = 1e-2)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "print(f\"Input: {len(X)} sentences up to {max_len} words, Word embedding: vocab_size {vocab_size} embedding_dim {embedding_dim}\")\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch % (n_epochs//10) == 1:\n",
    "        elapsed = time.time() - t\n",
    "        print(f\"epoch: {epoch}/{n_epochs}, loss: {loss} - {epoch * 100 // n_epochs}% complete, {elapsed} elapsed\")\n",
    "        \n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            Y_batch = Y_train[start:start+batch_size]\n",
    "            \n",
    "            # Ensure Y_batch is a 1D tensor of class indices\n",
    "            # Y_batch = Y_batch.view(-1)\n",
    "\n",
    "            # Check if input indices are within the valid range\n",
    "            if X_batch.max().item() >= vocab_size or X_batch.min().item() < 0:\n",
    "                raise ValueError(\"Input contains indices outside the range of the embedding layer\")\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(X_batch)           \n",
    "            loss = criterion(output, Y_batch)\n",
    "                                 \n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print progress\n",
    "            bar.set_postfix(loss=float(loss)) \n",
    "            \n",
    "    # evaluate accuracy at end of each epoch\n",
    "    Y_pred = model(X_test)\n",
    "    loss = criterion(Y_pred, Y_test)\n",
    "    history.append(loss)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# restore model and return best accuracy\n",
    "history_np = [h.detach().numpy() for h in history]\n",
    "\n",
    "print(\"Loss: %.2f\" % best_loss)\n",
    "plt.plot(history_np)\n",
    "plt.show()\n",
    "\n",
    "print(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0722bd14-ff39-492a-802e-ecc3e97e8c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Y_predicted = model(X_train)             # no need to call model.forward\n",
    "    Y_predicted = Y_predicted.view([-1, num_class]) # 3D to 2D\n",
    "    Y_train_2D = Y_train.view([-1, num_class]) # 3D to 2D\n",
    "    \n",
    "    Y_predicted_cls = torch.argmax(F.softmax(Y_predicted, dim=1), dim=1)  # Round off to nearest class\n",
    "    Y_train_cls = torch.argmax(F.softmax(Y_train_2D, dim=1), dim=1)\n",
    "    acc_train = Y_predicted_cls.eq(Y_train_cls).sum() / float(Y_train_cls.shape[0])  # accuracy\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_predicted = model(X_test)             # no need to call model.forward()\n",
    "    Y_predicted = Y_predicted.view([-1, num_class]) # 3D to 2D\n",
    "    Y_test_2D = Y_test.view([-1, num_class]) # 3D to 2D\n",
    "    \n",
    "    Y_predicted_cls = torch.argmax(F.softmax(Y_predicted, dim=1), dim=1)  # Round off to nearest class\n",
    "    Y_test_cls = torch.argmax(F.softmax(Y_test_2D, dim=1), dim=1)\n",
    "    acc_test = Y_predicted_cls.eq(Y_test_cls).sum().item() / float(Y_test_cls.shape[0])  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61f3dabb-1842-45a7-a724-30f5d6a9d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 8096 sentences up to 70 words, Word embedding: vocab_size 14551 embedding_dim 24\n",
      "accuracy with train set = 0.9366\n",
      "accuracy with test set = 0.9402\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input: {len(X)} sentences up to {max_len} words, Word embedding: vocab_size {vocab_size} embedding_dim {embedding_dim}\")\n",
    "print(f'accuracy with train set = {acc_train:.4f}')\n",
    "print(f'accuracy with test set = {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead6f96-b79d-45e4-ba6e-d6d492e9e0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
