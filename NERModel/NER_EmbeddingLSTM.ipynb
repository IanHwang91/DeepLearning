{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8090e10-ee4a-4c24-b1af-8008b65a64ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8192 entries, 0 to 8191\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  8192 non-null   object\n",
      " 1   Tag       8192 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 128.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Families of soldiers killed in the conflict jo...   \n",
       "2  They marched from the Houses of Parliament to ...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, f1_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import nltk\n",
    "# from wordcloud import WordCloud \n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.tokenize import wordpunct_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load Data from .csv file\n",
    "df = pd.read_csv(\"./TalkFile_ner_2.csv\")\n",
    "df.drop(['Sentence #', 'POS'], axis=1, inplace=True)\n",
    "df = df.dropna()  # Remove Blank Text\n",
    "\n",
    "# Limit data within in the first xxx line if needed\n",
    "df = df.iloc[:8192]\n",
    "\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9c1938-30c7-4159-8b40-9eca378e6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = \" \".join(df[\"Sentence\"]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f71b00-906e-4f1f-8a3e-46342d769b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'demonstrators', 'have', 'marched']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8654c42-7899-45f1-a716-c9a28d8251f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word indexing and Vectorization\n",
    "word2idx = {'<pad>': 0}\n",
    "word2idx.update({word: idx+1 for idx, word in enumerate(set(all_words))})\n",
    "vocab_size = len(word2idx)\n",
    "vocab_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9ef0f7-c6b7-4b1e-92a1-d7674fee9be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands',\n",
       " 'of',\n",
       " 'demonstrators',\n",
       " 'have',\n",
       " 'marched',\n",
       " 'through',\n",
       " 'London',\n",
       " 'to',\n",
       " 'protest',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'withdrawal',\n",
       " 'of',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'from',\n",
       " 'that',\n",
       " 'country',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences = df[\"Sentence\"].str.split()\n",
    "Sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223feefe-7477-4b75-bd9c-92d801c80663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove square brackets, commas, and quotation marks from the \"Tag\" column\n",
    "df[\"Tag_stripe\"] = df[\"Tag\"].str.replace(r\"[\\[\\]',]\", '', regex=True)\n",
    "\n",
    "# Combine all values in the \"Tag\" column into a single string\n",
    "cleaned_tags = \" \".join(df[\"Tag_stripe\"]).split()\n",
    "\n",
    "# Get unique tags\n",
    "unique_tags = set(cleaned_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c06926f-f8c3-4893-82c3-38269dced977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       O O O O O O B-geo O O O O O B-geo O O O O O B-...\n",
       "1       O O O O O O O O O O O O O O O O O O B-per O O ...\n",
       "2                     O O O O O O O O O O O B-geo I-geo O\n",
       "3                           O O O O O O O O O O O O O O O\n",
       "4       O O O O O O O O O O O B-geo O O B-org I-org O ...\n",
       "                              ...                        \n",
       "8187    O B-geo B-tim O B-geo O O O B-per I-per O O O ...\n",
       "8188    O B-tim O B-gpe O B-per O B-per I-per O O O O ...\n",
       "8189    O O O O O O O O O O B-geo O O B-gpe O O O O O ...\n",
       "8190    B-org I-org O O O O O O O O O O O O O O O O B-...\n",
       "8191                                    O O O O O O O O O\n",
       "Name: Tag_stripe, Length: 8192, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tag_stripe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e217c4e-4bc0-48ea-9157-f68d8feeb4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d745797b-9bca-45a2-b9e4-2b827558e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "list_labels = ['O'] + [i for i in list(unique_tags) if i !='O']\n",
    "\n",
    "label2ind = {}\n",
    "ind2label = {}\n",
    "for ind, i in enumerate(list_labels):\n",
    "    label2ind[i]=ind\n",
    "    ind2label[ind]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd569e5-b4bb-4c02-91df-7bac052e192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-art',\n",
       " 2: 'B-org',\n",
       " 3: 'B-tim',\n",
       " 4: 'I-nat',\n",
       " 5: 'I-eve',\n",
       " 6: 'I-per',\n",
       " 7: 'B-nat',\n",
       " 8: 'B-eve',\n",
       " 9: 'B-per',\n",
       " 10: 'I-org',\n",
       " 11: 'I-geo',\n",
       " 12: 'I-art',\n",
       " 13: 'I-gpe',\n",
       " 14: 'B-gpe',\n",
       " 15: 'I-tim',\n",
       " 16: 'B-geo'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24338416-a5e4-4231-b6da-3b8512982dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-art': 1,\n",
       " 'B-org': 2,\n",
       " 'B-tim': 3,\n",
       " 'I-nat': 4,\n",
       " 'I-eve': 5,\n",
       " 'I-per': 6,\n",
       " 'B-nat': 7,\n",
       " 'B-eve': 8,\n",
       " 'B-per': 9,\n",
       " 'I-org': 10,\n",
       " 'I-geo': 11,\n",
       " 'I-art': 12,\n",
       " 'I-gpe': 13,\n",
       " 'B-gpe': 14,\n",
       " 'I-tim': 15,\n",
       " 'B-geo': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e96ebdeb-0b11-4e9d-8390-edb6874a65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +1 for <pad>\n",
    "num_class = len(label2ind) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb73159-d5d0-483e-8ff1-07b3b6047973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8192 entries, 0 to 8191\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Sentence       8192 non-null   object\n",
      " 1   Tag            8192 non-null   object\n",
      " 2   Tag_stripe     8192 non-null   object\n",
      " 3   Encoded_Words  8192 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 256.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Tag_stripe</th>\n",
       "      <th>Encoded_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "      <td>[11804, 3818, 11591, 5909, 5496, 14054, 1392, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O B-per O O ...</td>\n",
       "      <td>[11507, 3818, 12475, 11697, 8840, 1335, 3312, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O B-geo I-geo O</td>\n",
       "      <td>[6016, 5496, 8755, 1335, 2811, 3818, 10290, 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O</td>\n",
       "      <td>[14297, 11726, 1335, 2517, 3818, 3133, 7271, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>O O O O O O O O O O O B-geo O O B-org I-org O ...</td>\n",
       "      <td>[9144, 14256, 10751, 10876, 1335, 179, 3818, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Families of soldiers killed in the conflict jo...   \n",
       "2  They marched from the Houses of Parliament to ...   \n",
       "3  Police put the number of marchers at 10,000 wh...   \n",
       "4  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...   \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "\n",
       "                                          Tag_stripe  \\\n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...   \n",
       "1  O O O O O O O O O O O O O O O O O O B-per O O ...   \n",
       "2                O O O O O O O O O O O B-geo I-geo O   \n",
       "3                      O O O O O O O O O O O O O O O   \n",
       "4  O O O O O O O O O O O B-geo O O B-org I-org O ...   \n",
       "\n",
       "                                       Encoded_Words  \n",
       "0  [11804, 3818, 11591, 5909, 5496, 14054, 1392, ...  \n",
       "1  [11507, 3818, 12475, 11697, 8840, 1335, 3312, ...  \n",
       "2  [6016, 5496, 8755, 1335, 2811, 3818, 10290, 65...  \n",
       "3  [14297, 11726, 1335, 2517, 3818, 3133, 7271, 4...  \n",
       "4  [9144, 14256, 10751, 10876, 1335, 179, 3818, 1...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to encode a list of words upto max_length\n",
    "def encode_sentence(words, word2idx, max_length):\n",
    "    # Encode words into indices, using 0 for unknown words\n",
    "    encoded = [word2idx.get(word, 0) for word in words]\n",
    "    \n",
    "    # Pad or truncate the list to match max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded.extend([0] * (max_length - len(encoded)))  # Pad with zeros\n",
    "    else:\n",
    "        encoded = encoded[:max_length]  # Truncate to max_length\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# Encode each list of words\n",
    "MAX_LEN = max(len(x) for x in Sentences)  # Ensure you have defined max_len appropriately\n",
    "max_len = MAX_LEN\n",
    "\n",
    "df[\"Encoded_Words\"] = Sentences.apply(lambda words: encode_sentence(words, word2idx, max_len))\n",
    "df.info()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b0b1aa1-185c-4971-899d-3b203b1d50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a list of POS or NER labels up to max_length\n",
    "def label_vectors(labels, max_length):\n",
    "    # Encode words into indices, using 0 for unknown words\n",
    "    encoded = [label2ind.get(label, len(label2ind)) for label in labels.split()]  # Use .get to handle unknown labels\n",
    "    \n",
    "    # Pad or truncate the list to match max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded.extend([len(label2ind)] * (max_length - len(encoded)))  # Pad with len(label2ind)\n",
    "    else:\n",
    "        encoded = encoded[:max_length]  # Truncate to max_length\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# Apply the function to the 'Tag' column and create a new column 'Label_Words'\n",
    "df[\"Label_Words\"] = df[\"Tag_stripe\"].apply(lambda labels: label_vectors(labels, max_len))\n",
    "\n",
    "df.drop(['Sentence', 'Tag_stripe', 'Tag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda68759-6ea8-4f68-a55a-a29db7d66c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split of the Dataset\n",
    "X = df[\"Encoded_Words\"].tolist()\n",
    "Y = df[\"Label_Words\"].tolist()\n",
    "\n",
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X, Y, train_size=0.8, random_state=101)\n",
    "\n",
    "# One hot for multi-class classification\n",
    "# NER = 17 classes [0-16] ==> num_class = 17 + 1 (padding)\n",
    "Y_trn_Oh = np.zeros((len(Y_trn), max_len, num_class))\n",
    "Y_tst_Oh = np.zeros((len(Y_tst), max_len, num_class))\n",
    "\n",
    "for i, y in enumerate(Y_trn):\n",
    "    Y_trn_Oh[i, np.arange(len(y)), y] = 1\n",
    "\n",
    "for i, y in enumerate(Y_tst):\n",
    "    Y_tst_Oh[i, np.arange(len(y)), y] = 1\n",
    "\n",
    "# Initialize an Embedding layer from Torch\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# Convert to word_vector Tensor \n",
    "X_train = torch.tensor(X_trn, dtype=torch.long)\n",
    "Y_train = torch.tensor(Y_trn_Oh, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_tst, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_tst_Oh, dtype=torch.float32)\n",
    "\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263d593a-f114-43aa-8418-cce557e3b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking parameters:  OrderedDict([('word_embedding.weight', tensor([[ 1.7650,  0.0664, -0.0706,  ...,  0.5088,  1.2001,  1.0033],\n",
      "        [ 0.2068, -0.6710,  0.4601,  ..., -1.6494, -0.8828,  0.4444],\n",
      "        [ 0.4656, -0.8964,  0.5814,  ...,  0.1931,  0.5177,  0.1250],\n",
      "        ...,\n",
      "        [ 0.9063,  0.0071,  2.0323,  ..., -0.6262, -1.2594, -0.8737],\n",
      "        [-1.0977, -0.9847, -0.5682,  ...,  3.3623,  1.6205,  0.0170],\n",
      "        [ 1.7196,  0.9410, -0.0274,  ...,  1.6649,  0.4239, -0.7282]])), ('lstm.weight_ih_l0', tensor([[ 0.1542,  0.0557, -0.1086,  ...,  0.1616,  0.0609,  0.0606],\n",
      "        [-0.0311, -0.0700, -0.0055,  ...,  0.1401, -0.1325,  0.2127],\n",
      "        [-0.0019,  0.2105,  0.0734,  ..., -0.1123, -0.1202, -0.0586],\n",
      "        ...,\n",
      "        [ 0.0142,  0.1700, -0.1445,  ...,  0.0162,  0.1360, -0.1954],\n",
      "        [-0.2420, -0.1140, -0.0293,  ..., -0.1045, -0.1317, -0.2325],\n",
      "        [ 0.2127,  0.0626,  0.0050,  ..., -0.1010, -0.0311,  0.2404]])), ('lstm.weight_hh_l0', tensor([[ 0.0605,  0.0705,  0.1081,  ...,  0.2023,  0.1576, -0.1483],\n",
      "        [ 0.2278,  0.1540, -0.1422,  ..., -0.1910,  0.2297, -0.0804],\n",
      "        [-0.0950,  0.1253,  0.1478,  ...,  0.0929, -0.0554, -0.2434],\n",
      "        ...,\n",
      "        [-0.1425,  0.0385, -0.1766,  ...,  0.1681, -0.2124, -0.0060],\n",
      "        [-0.2234, -0.2059, -0.0122,  ..., -0.0878,  0.1917,  0.0315],\n",
      "        [ 0.0810,  0.1764,  0.0767,  ..., -0.0915, -0.1515, -0.0446]])), ('lstm.bias_ih_l0', tensor([-0.2381,  0.0651,  0.0590, -0.0070, -0.0320, -0.0669, -0.0932,  0.0836,\n",
      "        -0.1716, -0.0564,  0.0769,  0.1302, -0.0256,  0.2473,  0.0507,  0.2236,\n",
      "         0.1440, -0.2424, -0.0522, -0.2181,  0.0530, -0.0211,  0.2394, -0.1540,\n",
      "        -0.0878, -0.2452,  0.2146, -0.0090,  0.1951,  0.1315, -0.2289,  0.1656,\n",
      "        -0.1692, -0.0654,  0.1248,  0.0461,  0.1207,  0.2341, -0.2373, -0.0807,\n",
      "         0.0471,  0.0745, -0.1291,  0.0360, -0.1337,  0.0986, -0.2478,  0.0290,\n",
      "        -0.1592, -0.1558, -0.2466,  0.2315, -0.0326,  0.0264, -0.0924, -0.0412,\n",
      "         0.1253, -0.0226,  0.1014, -0.0540, -0.0107, -0.2257, -0.2392, -0.0180])), ('lstm.bias_hh_l0', tensor([ 0.1443,  0.1711,  0.0927,  0.1823, -0.0432,  0.1755,  0.1718, -0.1640,\n",
      "         0.2307,  0.0696, -0.0961,  0.1943,  0.2393,  0.0126,  0.1514, -0.2439,\n",
      "         0.1051, -0.0154,  0.2237, -0.2034, -0.1114, -0.1665, -0.2118, -0.1376,\n",
      "         0.0198,  0.2109,  0.0131, -0.2143,  0.0082,  0.1627, -0.2258,  0.2029,\n",
      "         0.2210, -0.1979,  0.2498,  0.1042, -0.2345,  0.0645,  0.2057,  0.1856,\n",
      "         0.1729, -0.0078, -0.1814, -0.1909,  0.1069,  0.1191,  0.0860, -0.1552,\n",
      "        -0.2453,  0.1521, -0.0049,  0.1122,  0.0735,  0.0621,  0.1943,  0.1414,\n",
      "        -0.1390, -0.0150, -0.1066, -0.1905, -0.0098, -0.0990, -0.0159,  0.0408])), ('linear.weight', tensor([[-0.0212, -0.0412,  0.1819,  0.2405,  0.2187, -0.1113, -0.1611,  0.1661,\n",
      "          0.2260, -0.0693, -0.2085, -0.2135,  0.1800, -0.1085,  0.1309,  0.1710],\n",
      "        [ 0.0054, -0.0289,  0.1540,  0.0695,  0.1921,  0.1296,  0.0550, -0.1695,\n",
      "         -0.2445,  0.0370, -0.0466,  0.1249,  0.0784,  0.1916,  0.0137, -0.0351],\n",
      "        [-0.0733,  0.0174,  0.1809,  0.0406, -0.0046,  0.1066,  0.1304,  0.0259,\n",
      "         -0.0793, -0.0445, -0.2374,  0.1363,  0.1857, -0.0118, -0.1533,  0.0588],\n",
      "        [ 0.0507,  0.1215,  0.0338, -0.1227,  0.0869,  0.0148,  0.1255,  0.1645,\n",
      "         -0.1513,  0.2295, -0.0915,  0.2431, -0.1611,  0.0771,  0.2340, -0.0253],\n",
      "        [ 0.1485,  0.2110, -0.0390, -0.0679, -0.0783,  0.0113, -0.0527,  0.0130,\n",
      "          0.2158,  0.2262, -0.0672,  0.0547,  0.1261,  0.0172,  0.1055,  0.1270],\n",
      "        [ 0.1235,  0.0823, -0.2301,  0.1941,  0.2294, -0.2373, -0.1443, -0.2280,\n",
      "         -0.1302,  0.0915,  0.0397, -0.2031, -0.0266, -0.0373,  0.2401,  0.0428],\n",
      "        [-0.1811,  0.2048,  0.0742, -0.0030, -0.2256,  0.0401,  0.2001, -0.0937,\n",
      "          0.1802, -0.2368, -0.2402, -0.1569, -0.0954,  0.1700,  0.1895, -0.0656],\n",
      "        [-0.1924,  0.1736, -0.2126, -0.2437, -0.2481,  0.1797, -0.2277, -0.1016,\n",
      "          0.2030, -0.1574, -0.1900, -0.0687, -0.0832, -0.2236, -0.1977, -0.1149],\n",
      "        [-0.1796,  0.1115,  0.0131,  0.1439, -0.0209, -0.0650,  0.1829,  0.1180,\n",
      "         -0.1364,  0.0804, -0.0053, -0.0877, -0.0169, -0.1897,  0.2073, -0.0302],\n",
      "        [ 0.1567,  0.2457, -0.0940, -0.1364, -0.0900,  0.0777,  0.1522, -0.0333,\n",
      "         -0.0152, -0.1777,  0.2472,  0.1008, -0.1923, -0.2289, -0.1818,  0.1949],\n",
      "        [-0.1378, -0.0534,  0.0446, -0.1856,  0.1865,  0.0568,  0.0513, -0.2490,\n",
      "         -0.2019, -0.1294, -0.0545, -0.1211,  0.0495, -0.1262,  0.1014,  0.2301],\n",
      "        [-0.2453, -0.2260, -0.0374, -0.1436, -0.0430, -0.0993, -0.1994,  0.0810,\n",
      "         -0.1435,  0.1973,  0.0702,  0.1557, -0.0750, -0.1968,  0.1395,  0.1943],\n",
      "        [-0.2003, -0.0261, -0.1406, -0.0475,  0.1776, -0.0863, -0.0410,  0.1718,\n",
      "         -0.1264,  0.0499,  0.0321,  0.0064,  0.1750, -0.1674, -0.2447,  0.2170],\n",
      "        [-0.1685,  0.0294, -0.0616,  0.1283, -0.0753, -0.1693,  0.1377,  0.1612,\n",
      "         -0.2285,  0.1520,  0.0815,  0.1138,  0.0243, -0.2387,  0.0835, -0.0583],\n",
      "        [-0.2205,  0.2029,  0.2102,  0.0354, -0.1394, -0.0917, -0.1136,  0.2488,\n",
      "          0.0661, -0.1500, -0.1097,  0.2319, -0.1171,  0.0710, -0.0624,  0.0641],\n",
      "        [ 0.2298, -0.0146,  0.2088,  0.1825,  0.1043, -0.0062,  0.1315,  0.1477,\n",
      "         -0.2237,  0.2431, -0.2158,  0.0528,  0.0511, -0.0334, -0.2403, -0.0974],\n",
      "        [ 0.1608, -0.1468, -0.0110,  0.0925, -0.0194,  0.0802,  0.2374,  0.1416,\n",
      "          0.0006, -0.2116, -0.0254, -0.0462,  0.2153,  0.2161, -0.2087, -0.0065],\n",
      "        [-0.0288,  0.2043,  0.2376,  0.0492, -0.1896, -0.1584,  0.1737, -0.1223,\n",
      "          0.2178, -0.0684,  0.0501,  0.0313,  0.2491, -0.0916, -0.2102,  0.2365]])), ('linear.bias', tensor([ 0.0275,  0.2200,  0.1264, -0.1909, -0.1063, -0.1179,  0.0477,  0.0513,\n",
      "         0.2378,  0.2486,  0.1211,  0.1009, -0.0684, -0.1280, -0.1628, -0.2391,\n",
      "        -0.0540,  0.0241]))])\n"
     ]
    }
   ],
   "source": [
    "# Build Custom Module for logistic Regression\n",
    "class LogisticRegressionLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(LogisticRegressionLSTM, self).__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to tag space / class\n",
    "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        sentence = sentence.long()  # Convert input tensor to LongTensor for embedding layer input\n",
    "        embeds = self.word_embedding(sentence)  # Shape: (batch_size, sequence_length, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(embeds)  # Shape: (batch_size, sequence_length, hidden_dim)\n",
    "        y_pred = self.linear(lstm_out)  # Shape: (batch_size, sequence_length, output_dim)\n",
    "        return y_pred\n",
    "        \n",
    "# Instantiate the model\n",
    "torch.manual_seed(27)\n",
    "# num_class = 17\n",
    "# vocab_size = 35177\n",
    "embedding_dim = 32\n",
    "lstm_hidden_dim = 16\n",
    "\n",
    "model = LogisticRegressionLSTM(vocab_size, embedding_dim, lstm_hidden_dim, num_class)\n",
    "\n",
    "print(\"checking parameters: \", model.state_dict())\n",
    "\n",
    "# Defining Binary Cross-Entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f04d9d-d2a2-46bd-a77f-a2124d73195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 8192 sentences up to 70 words, Word embedding: vocab_size 14640 embedding_dim 32\n",
      "epoch: 1/128, loss: 15.209515571594238 - 0% complete, 1.6505391597747803 elapsed\n",
      "epoch: 13/128, loss: 14.2969388961792 - 10% complete, 22.259016036987305 elapsed\n",
      "epoch: 25/128, loss: 14.280817985534668 - 19% complete, 46.82952117919922 elapsed\n",
      "epoch: 37/128, loss: 14.274821281433105 - 28% complete, 68.46815466880798 elapsed\n",
      "epoch: 49/128, loss: 14.269701957702637 - 38% complete, 89.74947142601013 elapsed\n",
      "epoch: 61/128, loss: 14.266219139099121 - 47% complete, 111.00031423568726 elapsed\n",
      "epoch: 73/128, loss: 14.264802932739258 - 57% complete, 132.83511900901794 elapsed\n",
      "epoch: 85/128, loss: 14.264358520507812 - 66% complete, 157.05080604553223 elapsed\n",
      "epoch: 97/128, loss: 14.264178276062012 - 75% complete, 181.18426823616028 elapsed\n",
      "epoch: 109/128, loss: 14.264158248901367 - 85% complete, 205.90790152549744 elapsed\n",
      "epoch: 121/128, loss: 14.264225959777832 - 94% complete, 232.0024528503418 elapsed\n",
      "Loss: 14.26\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('word_embedding.weight', tensor([[ 4.8508e-01,  2.1812e-01, -8.4869e-02,  ...,  5.3807e-02,\n",
      "          4.4635e-02,  1.0922e-01],\n",
      "        [ 2.0617e-07,  8.5532e-08, -9.5767e-08,  ..., -1.1306e-07,\n",
      "         -2.0267e-08,  8.1572e-08],\n",
      "        [ 1.4639e-04, -3.8370e-05, -8.2182e-06,  ..., -1.0403e-05,\n",
      "          9.5050e-06,  2.2668e-05],\n",
      "        ...,\n",
      "        [-1.8066e-05,  1.2416e-05, -2.2915e-05,  ..., -3.6034e-06,\n",
      "          1.5475e-06, -4.0962e-06],\n",
      "        [ 7.3045e-06,  1.8976e-06, -1.9468e-06,  ...,  3.8831e-03,\n",
      "         -1.3408e-06, -6.3042e-06],\n",
      "        [-1.5481e-04, -9.9102e-05,  3.2838e-05,  ..., -1.7248e-05,\n",
      "          3.3287e-05, -3.7463e-05]])), ('lstm.weight_ih_l0', tensor([[ 0.0368,  0.0167, -0.0068,  ...,  0.0042,  0.0032,  0.0087],\n",
      "        [ 0.0694,  0.0310, -0.0122,  ...,  0.0078,  0.0064,  0.0156],\n",
      "        [ 0.0578,  0.0259, -0.0105,  ...,  0.0067,  0.0053,  0.0131],\n",
      "        ...,\n",
      "        [ 0.0611,  0.0274, -0.0108,  ...,  0.0068,  0.0056,  0.0137],\n",
      "        [ 0.0613,  0.0277, -0.0110,  ...,  0.0069,  0.0057,  0.0138],\n",
      "        [ 0.0817,  0.0363, -0.0139,  ...,  0.0087,  0.0072,  0.0179]])), ('lstm.weight_hh_l0', tensor([[-0.0229, -0.0111,  0.0041,  ..., -0.0229,  0.0092, -0.0005],\n",
      "        [-0.0310, -0.1125, -0.0515,  ..., -0.0309,  0.1054,  0.0441],\n",
      "        [-0.0267, -0.0613, -0.0240,  ..., -0.0266,  0.0569,  0.0226],\n",
      "        ...,\n",
      "        [-0.0573,  0.0174,  0.0382,  ..., -0.0573, -0.0204, -0.0439],\n",
      "        [-0.0512, -0.1376, -0.0550,  ..., -0.0510,  0.1277,  0.0299],\n",
      "        [-0.0544,  0.0150,  0.0346,  ..., -0.0544, -0.0178, -0.0369]])), ('lstm.bias_ih_l0', tensor([ 0.0820,  0.3200,  0.2037,  0.0819,  0.0828,  0.0819,  0.0826,  0.0822,\n",
      "         0.0819,  0.0819,  0.0825,  0.3195,  0.1089,  0.0821,  0.3069,  0.1086,\n",
      "         0.0576, -0.0013,  0.0089,  0.0577,  0.0572,  0.0577,  0.0573,  0.0576,\n",
      "         0.0577,  0.0576,  0.0574, -0.0013,  0.0758,  0.0575, -0.0022,  0.0760,\n",
      "        -0.0114, -0.2852, -0.1781, -0.0116, -0.0094,  0.0117,  0.0101, -0.0109,\n",
      "        -0.0117,  0.0115,  0.0100, -0.2848,  0.1278, -0.0111,  0.2740,  0.1280,\n",
      "         0.1201,  0.4144,  0.2662,  0.1201,  0.1214,  0.1200,  0.1210,  0.1207,\n",
      "         0.1200,  0.1201,  0.1209,  0.4137,  0.1199,  0.1204,  0.3969,  0.1199])), ('lstm.bias_hh_l0', tensor([ 0.0819,  0.3200,  0.2037,  0.0819,  0.0828,  0.0819,  0.0826,  0.0823,\n",
      "         0.0819,  0.0819,  0.0825,  0.3195,  0.1089,  0.0821,  0.3069,  0.1086,\n",
      "         0.0576, -0.0013,  0.0089,  0.0577,  0.0572,  0.0577,  0.0573,  0.0576,\n",
      "         0.0577,  0.0576,  0.0574, -0.0013,  0.0758,  0.0575, -0.0022,  0.0760,\n",
      "        -0.0114, -0.2852, -0.1781, -0.0116, -0.0094,  0.0117,  0.0101, -0.0109,\n",
      "        -0.0117,  0.0115,  0.0100, -0.2848,  0.1278, -0.0111,  0.2740,  0.1280,\n",
      "         0.1201,  0.4144,  0.2662,  0.1201,  0.1214,  0.1200,  0.1209,  0.1207,\n",
      "         0.1200,  0.1201,  0.1210,  0.4137,  0.1199,  0.1203,  0.3969,  0.1199])), ('linear.weight', tensor([[ 0.4305, -0.5951, -0.5446,  0.4303,  0.4320, -0.4303, -0.4319,  0.4309,\n",
      "          0.4303, -0.4305, -0.4314, -0.5951,  0.2600,  0.4308,  0.5919,  0.2601],\n",
      "        [ 0.0262, -0.0407, -0.0365,  0.0262,  0.0264, -0.0262, -0.0263,  0.0263,\n",
      "          0.0262, -0.0262, -0.0263, -0.0407,  0.0367,  0.0263,  0.0405,  0.0367],\n",
      "        [ 0.2037, -0.2135, -0.2169,  0.2037,  0.2040, -0.2037, -0.2039,  0.2038,\n",
      "          0.2037, -0.2037, -0.2039, -0.2137,  0.1759,  0.2038,  0.2161,  0.1758],\n",
      "        [ 0.1628, -0.2742, -0.2375,  0.1627,  0.1636, -0.1627, -0.1632,  0.1629,\n",
      "          0.1626, -0.1627, -0.1634, -0.2741,  0.2440,  0.1629,  0.2715,  0.2439],\n",
      "        [ 0.0086, -0.0128, -0.0116,  0.0086,  0.0086, -0.0086, -0.0086,  0.0086,\n",
      "          0.0086, -0.0086, -0.0086, -0.0128,  0.0120,  0.0086,  0.0128,  0.0120],\n",
      "        [ 0.0211, -0.0340, -0.0301,  0.0211,  0.0212, -0.0211, -0.0212,  0.0212,\n",
      "          0.0211, -0.0211, -0.0212, -0.0340,  0.0313,  0.0212,  0.0338,  0.0313],\n",
      "        [ 0.1785, -0.2444, -0.2245,  0.1785,  0.1791, -0.1785, -0.1789,  0.1787,\n",
      "          0.1785, -0.1785, -0.1789, -0.2444,  0.2028,  0.1786,  0.2441,  0.2027],\n",
      "        [ 0.0152, -0.0245, -0.0218,  0.0152,  0.0153, -0.0152, -0.0153,  0.0152,\n",
      "          0.0152, -0.0152, -0.0153, -0.0245,  0.0226,  0.0152,  0.0244,  0.0226],\n",
      "        [ 0.0241, -0.0385, -0.0342,  0.0241,  0.0242, -0.0241, -0.0241,  0.0241,\n",
      "          0.0241, -0.0241, -0.0241, -0.0385,  0.0352,  0.0241,  0.0382,  0.0352],\n",
      "        [ 0.2095, -0.1752, -0.1955,  0.2094,  0.2094, -0.2094, -0.2095,  0.2095,\n",
      "          0.2095, -0.2095, -0.2094, -0.1754,  0.1587,  0.2095,  0.1800,  0.1587],\n",
      "        [ 0.1546, -0.2423, -0.2140,  0.1545,  0.1553, -0.1545, -0.1550,  0.1547,\n",
      "          0.1544, -0.1545, -0.1551, -0.2423,  0.2043,  0.1547,  0.2404,  0.2041],\n",
      "        [ 0.1153, -0.2009, -0.1734,  0.1153,  0.1159, -0.1153, -0.1157,  0.1155,\n",
      "          0.1152, -0.1153, -0.1158, -0.2008,  0.1810,  0.1154,  0.1988,  0.1809],\n",
      "        [ 0.0159, -0.0247, -0.0221,  0.0159,  0.0160, -0.0159, -0.0160,  0.0160,\n",
      "          0.0159, -0.0159, -0.0159, -0.0247,  0.0227,  0.0159,  0.0246,  0.0227],\n",
      "        [ 0.0186, -0.0285, -0.0256,  0.0185,  0.0186, -0.0185, -0.0186,  0.0186,\n",
      "          0.0185, -0.0186, -0.0186, -0.0285,  0.0260,  0.0186,  0.0284,  0.0260],\n",
      "        [ 0.2017, -0.2037, -0.2103,  0.2016,  0.2019, -0.2016, -0.2019,  0.2017,\n",
      "          0.2016, -0.2017, -0.2018, -0.2038,  0.1722,  0.2017,  0.2067,  0.1722],\n",
      "        [ 0.1037, -0.1833, -0.1581,  0.1036,  0.1043, -0.1036, -0.1040,  0.1038,\n",
      "          0.1036, -0.1036, -0.1042, -0.1833,  0.1628,  0.1038,  0.1813,  0.1626],\n",
      "        [ 0.2052, -0.2977, -0.2690,  0.2051,  0.2059, -0.2051, -0.2056,  0.2053,\n",
      "          0.2051, -0.2052, -0.2057, -0.2977,  0.2631,  0.2053,  0.2964,  0.2630],\n",
      "        [-0.2631,  1.0079,  0.5803, -0.2626, -0.2659,  0.2627,  0.2661, -0.2640,\n",
      "         -0.2627,  0.2631,  0.2647,  1.0050,  0.6248, -0.2639, -0.9408,  0.6225]])), ('linear.bias', tensor([ 6.9246e-05, -1.1241e-08,  1.0427e-07, -1.2949e-07,  1.7510e-08,\n",
      "        -3.0380e-08, -3.2922e-07, -1.6020e-08,  7.2565e-09,  3.2129e-08,\n",
      "         2.8341e-08, -7.4321e-09, -3.4746e-08,  6.4759e-09, -1.2670e-07,\n",
      "        -2.1830e-08,  8.4502e-07, -4.8026e-05]))])\n"
     ]
    }
   ],
   "source": [
    "# Hold the best model\n",
    "best_loss = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "n_epochs = 128  # number of epochs to run\n",
    "batch_size = 64 # size of each batch\n",
    "\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay = 1e-2)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "print(f\"Input: {len(X)} sentences up to {max_len} words, Word embedding: vocab_size {vocab_size} embedding_dim {embedding_dim}\")\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch % (n_epochs//10) == 1:\n",
    "        elapsed = time.time() - t\n",
    "        print(f\"epoch: {epoch}/{n_epochs}, loss: {loss} - {epoch * 100 // n_epochs}% complete, {elapsed} elapsed\")\n",
    "        \n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            Y_batch = Y_train[start:start+batch_size]\n",
    "            \n",
    "            # Ensure Y_batch is a 1D tensor of class indices\n",
    "            # Y_batch = Y_batch.view(-1)\n",
    "\n",
    "            # Check if input indices are within the valid range\n",
    "            if X_batch.max().item() >= vocab_size or X_batch.min().item() < 0:\n",
    "                raise ValueError(\"Input contains indices outside the range of the embedding layer\")\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(X_batch)           \n",
    "            loss = criterion(output, Y_batch)\n",
    "                                 \n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print progress\n",
    "            bar.set_postfix(loss=float(loss)) \n",
    "            \n",
    "    # evaluate accuracy at end of each epoch\n",
    "    Y_pred = model(X_test)\n",
    "    loss = criterion(Y_pred, Y_test)\n",
    "    history.append(loss)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# restore model and return best accuracy\n",
    "history_np = [h.detach().numpy() for h in history]\n",
    "\n",
    "print(\"Loss: %.2f\" % best_loss)\n",
    "plt.plot(history_np)\n",
    "plt.show()\n",
    "\n",
    "print(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0722bd14-ff39-492a-802e-ecc3e97e8c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Y_predicted = model(X_train)             # no need to call model.forward\n",
    "    Y_predicted = Y_predicted.view([-1, num_class]) # 3D to 2D\n",
    "    Y_train_2D = Y_train.view([-1, num_class]) # 3D to 2D\n",
    "    \n",
    "    Y_predicted_cls = torch.argmax(F.softmax(Y_predicted, dim=1), dim=1)  # Round off to nearest class\n",
    "    Y_train_cls = torch.argmax(F.softmax(Y_train_2D, dim=1), dim=1)\n",
    "    acc_train = Y_predicted_cls.eq(Y_train_cls).sum() / float(Y_train_cls.shape[0])  # accuracy\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_predicted = model(X_test)             # no need to call model.forward()\n",
    "    Y_predicted = Y_predicted.view([-1, num_class]) # 3D to 2D\n",
    "    Y_test_2D = Y_test.view([-1, num_class]) # 3D to 2D\n",
    "    \n",
    "    Y_predicted_cls = torch.argmax(F.softmax(Y_predicted, dim=1), dim=1)  # Round off to nearest class\n",
    "    Y_test_cls = torch.argmax(F.softmax(Y_test_2D, dim=1), dim=1)\n",
    "    acc_test = Y_predicted_cls.eq(Y_test_cls).sum().item() / float(Y_test_cls.shape[0])  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61f3dabb-1842-45a7-a724-30f5d6a9d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 8192 sentences up to 70 words, Word embedding: vocab_size 14640 embedding_dim 32\n",
      "accuracy with train set = 0.9519\n",
      "accuracy with test set = 0.9531\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input: {len(X)} sentences up to {max_len} words, Word embedding: vocab_size {vocab_size} embedding_dim {embedding_dim}\")\n",
    "print(f'accuracy with train set = {acc_train:.4f}')\n",
    "print(f'accuracy with test set = {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75004e9c-8030-49f5-a768-bcf2b24f51d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
